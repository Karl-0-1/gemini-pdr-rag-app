{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "huIKO7v5gEdP"
      },
      "outputs": [],
      "source": [
        "!pip install langchain langchain-google-genai pypdf chromadb langchain_community langchain_core"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "try:\n",
        "    # Use the key from Colab Secrets\n",
        "    os.environ['GOOGLE_API_KEY'] = userdata.get('GEMINI_API_KEY')\n",
        "except:\n",
        "    # Fallback for direct input if you don't use Colab Secrets (less secure)\n",
        "    print(\"Warning: 'GEMINI_API_KEY' not found in Colab Secrets. Prompting for manual input.\")\n",
        "    from getpass import getpass\n",
        "    os.environ['GOOGLE_API_KEY'] = getpass(\"Enter your Gemini API Key: \")"
      ],
      "metadata": {
        "id": "eBC5JtHQgKHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain.retrievers import ParentDocumentRetriever\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.chains import ConversationalRetrievalChain # Moved from the failing cell\n",
        "from langchain.memory import ConversationBufferMemory # Moved from the failing cell\n",
        "\n",
        "# --- Configuration (unchanged) ---\n",
        "# path of pdf\n",
        "PDF_FILE_NAME = \"/content/2024-wttc-introduction-to-ai.pdf\"\n",
        "LLM_MODEL = \"gemini-2.5-flash\"\n",
        "EMBEDDING_MODEL = \"models/embedding-001\"\n",
        "VECTOR_DB_PATH = \"./chroma_colab_db\"\n",
        "\n",
        "def setup_rag_chain(file_path: str):\n",
        "    # 1. Load Documents\n",
        "    loader = PyPDFLoader(file_path)\n",
        "    data = loader.load_and_split()\n",
        "\n",
        "    # --- 2. Define Parent and Child Splitters ---\n",
        "    parent_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=200)\n",
        "    child_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=100)\n",
        "\n",
        "    # --- 3. Setup Storage ---\n",
        "    embeddings = GoogleGenerativeAIEmbeddings(model=EMBEDDING_MODEL)\n",
        "    vectorstore = Chroma.from_documents(data, embeddings)\n",
        "    store = InMemoryStore()\n",
        "\n",
        "    # --- 4. Create Parent Document Retriever ---\n",
        "    retriever = ParentDocumentRetriever(\n",
        "        vectorstore=vectorstore,\n",
        "        docstore=store,\n",
        "        child_splitter=child_splitter,\n",
        "        parent_splitter=parent_splitter,\n",
        "    )\n",
        "    retriever.add_documents(data)\n",
        "    print(\"RAG chain setup complete using Parent Document Retriever.\")\n",
        "\n",
        "    # --- 5. Build the RAG Chain ---\n",
        "    llm = ChatGoogleGenerativeAI(model=LLM_MODEL, temperature=0.2)\n",
        "    prompt_template = \"\"\"You are an expert Q&A assistant... (use the same strong prompt) ...\n",
        "    Context: {context}\n",
        "    Question: {question}\n",
        "    \"\"\"\n",
        "    prompt = ChatPromptTemplate.from_template(prompt_template)\n",
        "    rag_chain = (\n",
        "        {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "        | prompt\n",
        "        | llm\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "\n",
        "    # --- 6. Setup Conversational Retrieval Chain (Moved from the failing cell) ---\n",
        "    llm_with_history = ChatGoogleGenerativeAI(model=LLM_MODEL, temperature=0.2)\n",
        "    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "    qa_chain = ConversationalRetrievalChain.from_llm(\n",
        "        llm=llm_with_history,\n",
        "        retriever=retriever, # Use the robust PDR you already built\n",
        "        memory=memory\n",
        "    )\n",
        "    print(\"Conversational Retrieval Chain setup complete.\")\n",
        "\n",
        "    return rag_chain, qa_chain # Return both chains\n",
        "\n",
        "# Execute the setup\n",
        "rag_chain, qa_chain = setup_rag_chain(PDF_FILE_NAME)"
      ],
      "metadata": {
        "id": "iken0N7Tg4D1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple command-line loop for testing in Colab\n",
        "print(\"-\" * 50)\n",
        "print(\"Welcome! Ask a question about your document.\")\n",
        "print(\"Type 'quit' or 'exit' to end the session.\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() in [\"quit\", \"exit\"]:\n",
        "        print(\"Assistant: Goodbye!\")\n",
        "        break\n",
        "\n",
        "    # Invoke the Conversational Retrieval Chain\n",
        "    try:\n",
        "        response = qa_chain.invoke({\"question\": user_input})\n",
        "        print(f\"Assistant: {response['answer']}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        print(\"Please check your API key and document setup.\")"
      ],
      "metadata": {
        "id": "snJeE28Uhts7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1EA0ENw7qawZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}